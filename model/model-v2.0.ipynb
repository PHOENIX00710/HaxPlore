{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import JSON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('intents.json')\n",
    "df['text'] = df['intents'].apply(lambda x: x['dialogue'])\n",
    "df['intent'] = df['intents'].apply(lambda x: x['intent'])\n",
    "df.drop('intents', axis=1, inplace=True)\n",
    "df.head()\n",
    "\n",
    "f = open('intents.csv', 'w')\n",
    "df['text'].to_csv(f, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset='text', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intent\n",
       "History         36\n",
       "Book            34\n",
       "Cancel          32\n",
       "Location        32\n",
       "About           29\n",
       "Availability    26\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['intent'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer,TFBertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "df['tokenized'] = df['text'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True, return_tensors='tf'))\n",
    "df['embeddings'] = [model(token).pooler_output for token in df['tokenized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rishabh\\AppData\\Local\\Temp\\ipykernel_26476\\3622762613.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['intent'] = df['intent'].replace(correspondence, inplace=False)\n"
     ]
    }
   ],
   "source": [
    "correspondence = {'History':0,'Book':1,'Cancel':2,'Location':3,'About':4,'Availability':5}\n",
    "reversed_correspondence = {v:k for k,v in correspondence.items()}\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "df['intent'] = df['intent'].replace(correspondence, inplace=False)\n",
    "X = df['embeddings'].values\n",
    "y = df['intent'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train = np.concatenate([tensor.numpy() for tensor in X_train])\n",
    "X_test = np.concatenate([tensor.numpy() for tensor in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 1s 47ms/step - loss: 1.0813 - accuracy: 0.1921 - val_loss: -2.3746 - val_accuracy: 0.1316\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: -3.0029 - accuracy: 0.1921 - val_loss: -5.0645 - val_accuracy: 0.1316\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -5.2888 - accuracy: 0.1921 - val_loss: -6.8571 - val_accuracy: 0.1316\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -6.9312 - accuracy: 0.1921 - val_loss: -8.0730 - val_accuracy: 0.1316\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -7.9549 - accuracy: 0.1921 - val_loss: -8.9317 - val_accuracy: 0.1316\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: -8.9319 - accuracy: 0.1921 - val_loss: -9.5702 - val_accuracy: 0.1316\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: -9.5222 - accuracy: 0.1921 - val_loss: -10.1139 - val_accuracy: 0.1316\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -10.0977 - accuracy: 0.1921 - val_loss: -10.6129 - val_accuracy: 0.1316\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -10.5769 - accuracy: 0.1921 - val_loss: -11.0906 - val_accuracy: 0.1316\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -11.0701 - accuracy: 0.1921 - val_loss: -11.5535 - val_accuracy: 0.1316\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -11.5204 - accuracy: 0.1921 - val_loss: -12.0103 - val_accuracy: 0.1316\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -11.9878 - accuracy: 0.1921 - val_loss: -12.4713 - val_accuracy: 0.1316\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -12.4212 - accuracy: 0.1921 - val_loss: -12.9369 - val_accuracy: 0.1316\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -12.8899 - accuracy: 0.1921 - val_loss: -13.3922 - val_accuracy: 0.1316\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -13.3320 - accuracy: 0.1921 - val_loss: -13.8418 - val_accuracy: 0.1316\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -13.7984 - accuracy: 0.1921 - val_loss: -14.2808 - val_accuracy: 0.1316\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -14.2144 - accuracy: 0.1921 - val_loss: -14.7262 - val_accuracy: 0.1316\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -14.6659 - accuracy: 0.1921 - val_loss: -15.1601 - val_accuracy: 0.1316\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -15.0990 - accuracy: 0.1921 - val_loss: -15.5934 - val_accuracy: 0.1316\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -15.5241 - accuracy: 0.1921 - val_loss: -16.0317 - val_accuracy: 0.1316\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -15.9589 - accuracy: 0.1921 - val_loss: -16.4717 - val_accuracy: 0.1316\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -16.4056 - accuracy: 0.1921 - val_loss: -16.8994 - val_accuracy: 0.1316\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -16.8156 - accuracy: 0.1921 - val_loss: -17.3367 - val_accuracy: 0.1316\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -17.2416 - accuracy: 0.1921 - val_loss: -17.7741 - val_accuracy: 0.1316\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -17.6770 - accuracy: 0.1921 - val_loss: -18.2082 - val_accuracy: 0.1316\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -18.1006 - accuracy: 0.1921 - val_loss: -18.6495 - val_accuracy: 0.1316\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -18.5460 - accuracy: 0.1921 - val_loss: -19.0943 - val_accuracy: 0.1316\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -18.9900 - accuracy: 0.1921 - val_loss: -19.5412 - val_accuracy: 0.1316\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -19.4381 - accuracy: 0.1921 - val_loss: -19.9848 - val_accuracy: 0.1316\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -19.8849 - accuracy: 0.1921 - val_loss: -20.4252 - val_accuracy: 0.1316\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -20.3124 - accuracy: 0.1921 - val_loss: -20.8719 - val_accuracy: 0.1316\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -20.7569 - accuracy: 0.1921 - val_loss: -21.3126 - val_accuracy: 0.1316\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -21.1745 - accuracy: 0.1921 - val_loss: -21.7605 - val_accuracy: 0.1316\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -21.6268 - accuracy: 0.1921 - val_loss: -22.1981 - val_accuracy: 0.1316\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -22.0657 - accuracy: 0.1921 - val_loss: -22.6296 - val_accuracy: 0.1316\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -22.4767 - accuracy: 0.1921 - val_loss: -23.0686 - val_accuracy: 0.1316\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -22.8845 - accuracy: 0.1921 - val_loss: -23.5136 - val_accuracy: 0.1316\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -23.3422 - accuracy: 0.1921 - val_loss: -23.9381 - val_accuracy: 0.1316\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -23.7878 - accuracy: 0.1921 - val_loss: -24.3572 - val_accuracy: 0.1316\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -24.1925 - accuracy: 0.1921 - val_loss: -24.7907 - val_accuracy: 0.1316\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -24.6165 - accuracy: 0.1921 - val_loss: -25.2261 - val_accuracy: 0.1316\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -25.0363 - accuracy: 0.1921 - val_loss: -25.6632 - val_accuracy: 0.1316\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -25.4534 - accuracy: 0.1921 - val_loss: -26.1043 - val_accuracy: 0.1316\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -25.9143 - accuracy: 0.1921 - val_loss: -26.5305 - val_accuracy: 0.1316\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -26.3315 - accuracy: 0.1921 - val_loss: -26.9606 - val_accuracy: 0.1316\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -26.7686 - accuracy: 0.1921 - val_loss: -27.3853 - val_accuracy: 0.1316\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -27.1904 - accuracy: 0.1921 - val_loss: -27.8116 - val_accuracy: 0.1316\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -27.5910 - accuracy: 0.1921 - val_loss: -28.2471 - val_accuracy: 0.1316\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -28.0356 - accuracy: 0.1921 - val_loss: -28.6731 - val_accuracy: 0.1316\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -28.4636 - accuracy: 0.1921 - val_loss: -29.0991 - val_accuracy: 0.1316\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -28.8607 - accuracy: 0.1921 - val_loss: -29.5352 - val_accuracy: 0.1316\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -29.3168 - accuracy: 0.1921 - val_loss: -29.9507 - val_accuracy: 0.1316\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -29.7109 - accuracy: 0.1921 - val_loss: -30.3843 - val_accuracy: 0.1316\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -30.1164 - accuracy: 0.1921 - val_loss: -30.8228 - val_accuracy: 0.1316\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -30.5550 - accuracy: 0.1921 - val_loss: -31.2525 - val_accuracy: 0.1316\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -30.9865 - accuracy: 0.1921 - val_loss: -31.6776 - val_accuracy: 0.1316\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -31.4097 - accuracy: 0.1921 - val_loss: -32.1032 - val_accuracy: 0.1316\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -31.8398 - accuracy: 0.1921 - val_loss: -32.5250 - val_accuracy: 0.1316\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -32.2537 - accuracy: 0.1921 - val_loss: -32.9513 - val_accuracy: 0.1316\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: -32.6819 - accuracy: 0.1921 - val_loss: -33.3802 - val_accuracy: 0.1316\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -33.0770 - accuracy: 0.1921 - val_loss: -33.8212 - val_accuracy: 0.1316\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -33.5382 - accuracy: 0.1921 - val_loss: -34.2415 - val_accuracy: 0.1316\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -33.9347 - accuracy: 0.1921 - val_loss: -34.6737 - val_accuracy: 0.1316\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -34.3780 - accuracy: 0.1921 - val_loss: -35.0962 - val_accuracy: 0.1316\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -34.8065 - accuracy: 0.1921 - val_loss: -35.5194 - val_accuracy: 0.1316\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -35.2015 - accuracy: 0.1921 - val_loss: -35.9569 - val_accuracy: 0.1316\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -35.6345 - accuracy: 0.1921 - val_loss: -36.3883 - val_accuracy: 0.1316\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -36.0768 - accuracy: 0.1921 - val_loss: -36.8154 - val_accuracy: 0.1316\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -36.4861 - accuracy: 0.1921 - val_loss: -37.2634 - val_accuracy: 0.1316\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -36.9400 - accuracy: 0.1921 - val_loss: -37.7081 - val_accuracy: 0.1316\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -37.3675 - accuracy: 0.1921 - val_loss: -38.1573 - val_accuracy: 0.1316\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -37.8138 - accuracy: 0.1921 - val_loss: -38.6099 - val_accuracy: 0.1316\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -38.2675 - accuracy: 0.1921 - val_loss: -39.0843 - val_accuracy: 0.1316\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -38.7331 - accuracy: 0.1921 - val_loss: -39.5582 - val_accuracy: 0.1316\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -39.2118 - accuracy: 0.1921 - val_loss: -40.0560 - val_accuracy: 0.1316\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: -39.7280 - accuracy: 0.1921 - val_loss: -40.5434 - val_accuracy: 0.1316\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -40.1859 - accuracy: 0.1921 - val_loss: -41.0394 - val_accuracy: 0.1316\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -40.6732 - accuracy: 0.1921 - val_loss: -41.5275 - val_accuracy: 0.1316\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -41.1664 - accuracy: 0.1921 - val_loss: -42.0126 - val_accuracy: 0.1316\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: -41.6278 - accuracy: 0.1921 - val_loss: -42.5022 - val_accuracy: 0.1316\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -42.1211 - accuracy: 0.1921 - val_loss: -42.9822 - val_accuracy: 0.1316\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -42.5837 - accuracy: 0.1921 - val_loss: -43.4650 - val_accuracy: 0.1316\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -43.0623 - accuracy: 0.1921 - val_loss: -43.9405 - val_accuracy: 0.1316\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -43.5334 - accuracy: 0.1921 - val_loss: -44.4159 - val_accuracy: 0.1316\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -44.0203 - accuracy: 0.1921 - val_loss: -44.8814 - val_accuracy: 0.1316\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -44.4507 - accuracy: 0.1921 - val_loss: -45.3650 - val_accuracy: 0.1316\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -44.9261 - accuracy: 0.1921 - val_loss: -45.8370 - val_accuracy: 0.1316\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -45.3866 - accuracy: 0.1921 - val_loss: -46.3062 - val_accuracy: 0.1316\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -45.8704 - accuracy: 0.1921 - val_loss: -46.7616 - val_accuracy: 0.1316\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 37ms/step - loss: -46.3109 - accuracy: 0.1921 - val_loss: -47.2285 - val_accuracy: 0.1316\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: -46.7768 - accuracy: 0.1921 - val_loss: -47.6899 - val_accuracy: 0.1316\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -47.2428 - accuracy: 0.1921 - val_loss: -48.1488 - val_accuracy: 0.1316\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -47.7032 - accuracy: 0.1921 - val_loss: -48.6081 - val_accuracy: 0.1316\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -48.1389 - accuracy: 0.1921 - val_loss: -49.0802 - val_accuracy: 0.1316\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -48.6234 - accuracy: 0.1921 - val_loss: -49.5414 - val_accuracy: 0.1316\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -49.0607 - accuracy: 0.1921 - val_loss: -50.0114 - val_accuracy: 0.1316\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: -49.5269 - accuracy: 0.1921 - val_loss: -50.4771 - val_accuracy: 0.1316\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: -49.9775 - accuracy: 0.1921 - val_loss: -50.9448 - val_accuracy: 0.1316\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: -50.4396 - accuracy: 0.1921 - val_loss: -51.4066 - val_accuracy: 0.1316\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: -50.9120 - accuracy: 0.1921 - val_loss: -51.8564 - val_accuracy: 0.1316\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "callback = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=768, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='sigmoid')) \n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='sigmoid')) \n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "hist = model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), callbacks=[callback])\n",
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rishabh\\AppData\\Local\\Temp\\ipykernel_26476\\1891102389.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_new['intent'].replace(reversed_correspondence,inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>History</td>\n",
       "      <td>What is the history of the temple? History Can...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Book</td>\n",
       "      <td>How to book ticket? Is it possible to schedule...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cancel</td>\n",
       "      <td>Cancel a ticket Hi, I need to cancel my upcomi...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Location</td>\n",
       "      <td>Where is the temple located? Location Can you ...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>About</td>\n",
       "      <td>Tell me about the temple  What is the signific...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Availability</td>\n",
       "      <td>Any tickets available from 15th April to 20th ...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         intent                                      combined_text  similarity\n",
       "0       History  What is the history of the temple? History Can...          39\n",
       "1          Book  How to book ticket? Is it possible to schedule...          29\n",
       "2        Cancel  Cancel a ticket Hi, I need to cancel my upcomi...          32\n",
       "3      Location  Where is the temple located? Location Can you ...          39\n",
       "4         About  Tell me about the temple  What is the signific...          32\n",
       "5  Availability  Any tickets available from 15th April to 20th ...          29"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "dictionary = {'intent':[],'combined_text':[],'similarity':[]}\n",
    "for i in range(6):\n",
    "    dictionary['intent'].append(i)\n",
    "    dictionary['combined_text'].append(' '.join(df[df['intent']==i]['text'].values))\n",
    "    dictionary['similarity'].append(np.nan)\n",
    "df_new = pd.DataFrame(dictionary)\n",
    "df_new['intent'].replace(reversed_correspondence,inplace=True)\n",
    "name = input('Enter text: ')\n",
    "df_new['similarity'] = df_new['combined_text'].apply(lambda x: fuzz.partial_ratio(x,name))\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rishabh\\AppData\\Local\\Temp\\ipykernel_26476\\1703778463.py:5: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  print(df_new.iloc[i]['intent'], \" -> \",nlp(name).similarity(nlp(df_new.iloc[i]['combined_text'])))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History  ->  0.564681918849925\n",
      "Book  ->  0.5526458447059821\n",
      "Cancel  ->  0.4572201926491917\n",
      "Location  ->  0.6114424142237456\n",
      "About  ->  0.5695678889446457\n",
      "Availability  ->  0.4602208883740392\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "name = input('Enter text: ')\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "for i in range(6):\n",
    "    print(df_new.iloc[i]['intent'], \" -> \",nlp(name).similarity(nlp(df_new.iloc[i]['combined_text'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me about the temple\n",
      " What is the significance of this mandir?\n",
      "Can you tell me a story about the mandir?\n",
      "Is there anything special about the architecture of this mandir?\n",
      "I'm curious about the mandir, can you tell me something about it?\n",
      "I would be grateful if you could share information on the temple's architectural style and significant features.\n",
      "The temple's deities are of particular interest to me. Could you elaborate on them?\n",
      "Is there a website or brochure available with a detailed description of the temple layout and facilities?\n",
      "I would appreciate any insights you can offer regarding the temple's daily rituals and ceremonies.\n",
      "Could you outline the key structures and shrines located within the temple grounds?\n",
      "If available, I would be interested in learning about any festivals or special events unique to the temple.\n",
      "For planning purposes, are there specific opening and closing hours for the temple?\n",
      "Does the temple have any specific dress code requirements for visitors?\n",
      "I would appreciate any information you can offer regarding the significance of the temple within the local community.\n",
      "Could you share some historical background on the temple's construction?\n",
      "What are the materials and techniques used in the temple's architecture?\n",
      "Are there any specific stories or legends associated with the temple's deities?\n",
      "Is there a digital resource available with a floor plan or map of the temple grounds?\n",
      "I would be interested in learning about the offerings traditionally made by visitors to the temple.\n",
      "What are some of the symbolic elements incorporated into the temple's design?\n",
      "Does the temple hold any historical artifacts or relics of significance?\n",
      "Are there any specific days or times considered particularly auspicious for visiting the temple?\n",
      "Does the temple offer any facilities or services for pilgrims, such as accommodation or dining?\n",
      "I would appreciate any information you can share regarding the ongoing preservation efforts for the temple.\n",
      "May I inquire about the historical context surrounding the temple's establishment?\n",
      "What are the architectural influences evident in the temple's design?\n",
      "Are there any mythological narratives associated with the temple's origin?\n",
      "Is there an online resource with a comprehensive virtual tour of the temple?\n",
      "I would be interested in the types of offerings visitors typically bring to the temple.\n"
     ]
    }
   ],
   "source": [
    "for row in df[df['intent']=='About']['text'].values:\n",
    "    print(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
